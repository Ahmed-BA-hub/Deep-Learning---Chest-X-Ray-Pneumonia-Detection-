{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ff9a2ad5-1bb6-4f48-b70d-48d8621d78a1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\ud83d\udccb Model Config:\n",
            "   model_name: EfficientNet-B0\n",
            "   input_size: 224\n",
            "   num_classes: 2\n",
            "   class_names: ['NORMAL', 'PNEUMONIA']\n",
            "   center_crop_ratio: 0.7\n",
            "\n",
            "\u2705 Model loaded on cuda\n",
            "\u2705 Config loaded \u2014 ready for deployment\n",
            "\n",
            "\ud83e\uddea Quick inference test...\n",
            "   Test prediction: PNEUMONIA (100.0%)\n",
            "\u2705 Inference pipeline working!\n"
          ]
        }
      ],
      "source": [
        "# ============================================\n",
        "# Cell 0: Load Model for Deployment\n",
        "# ============================================\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import json\n",
        "import os\n",
        "from torchvision.models import efficientnet_b0\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "# Load config\n",
        "with open(\"model_config.json\", \"r\") as f:\n",
        "    config = json.load(f)\n",
        "\n",
        "print(\"\ud83d\udccb Model Config:\")\n",
        "for k, v in config.items():\n",
        "    if not isinstance(v, dict):\n",
        "        print(f\"   {k}: {v}\")\n",
        "\n",
        "# Load model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = efficientnet_b0(weights=None)\n",
        "model.classifier[1] = nn.Linear(1280, config[\"num_classes\"])\n",
        "model.load_state_dict(torch.load(\"best_model_crop.pt\", map_location=device))\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "print(f\"\\n\u2705 Model loaded on {device}\")\n",
        "print(f\"\u2705 Config loaded \u2014 ready for deployment\")\n",
        "\n",
        "# Center crop transform (same as training)\n",
        "class DynamicCenterCrop:\n",
        "    def __init__(self, ratio=0.7):\n",
        "        self.ratio = ratio\n",
        "    def __call__(self, img):\n",
        "        w, h = img.size\n",
        "        new_w = int(w * self.ratio)\n",
        "        new_h = int(h * self.ratio)\n",
        "        left = (w - new_w) // 2\n",
        "        top = (h - new_h) // 2\n",
        "        return img.crop((left, top, left + new_w, top + new_h))\n",
        "\n",
        "inference_transform = transforms.Compose([\n",
        "    transforms.Lambda(lambda img: img.convert('RGB')),\n",
        "    DynamicCenterCrop(config[\"center_crop_ratio\"]),\n",
        "    transforms.Resize((config[\"input_size\"], config[\"input_size\"])),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=config[\"normalization\"][\"mean\"], \n",
        "                         std=config[\"normalization\"][\"std\"])\n",
        "])\n",
        "\n",
        "# Quick test\n",
        "print(\"\\n\ud83e\uddea Quick inference test...\")\n",
        "test_img = Image.new('RGB', (300, 300), color='gray')\n",
        "tensor = inference_transform(test_img).unsqueeze(0).to(device)\n",
        "with torch.no_grad():\n",
        "    output = model(tensor)\n",
        "    probs = torch.softmax(output, dim=1)\n",
        "print(f\"   Test prediction: {config['class_names'][probs.argmax().item()]} ({probs.max().item()*100:.1f}%)\")\n",
        "print(\"\u2705 Inference pipeline working!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "08a12a54-e6ff-446e-ab38-e35dda68cd22",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "  GENERATING DEPLOYMENT FILES\n",
            "============================================================\n",
            "\u2705 Created: app.py (FastAPI backend)\n",
            "\u2705 Created: streamlit_app.py (Streamlit frontend)\n",
            "\u2705 Created: Dockerfile\n",
            "\u2705 Created: docker-compose.yml\n",
            "\u2705 Created: requirements.txt\n",
            "\u2705 Created: test_app.py (Pytest tests)\n",
            "\n",
            "============================================================\n",
            "  ALL DEPLOYMENT FILES CREATED\n",
            "============================================================\n",
            "\n",
            "\ud83d\udcc1 Project Structure:\n",
            "\u251c\u2500\u2500 best_model_crop.pt      (trained model)\n",
            "\u251c\u2500\u2500 model_config.json       (config & metrics)\n",
            "\u251c\u2500\u2500 app.py                  (FastAPI backend)\n",
            "\u251c\u2500\u2500 streamlit_app.py        (Streamlit frontend)\n",
            "\u251c\u2500\u2500 test_app.py             (Pytest tests)\n",
            "\u251c\u2500\u2500 requirements.txt        (dependencies)\n",
            "\u251c\u2500\u2500 Dockerfile              \n",
            "\u251c\u2500\u2500 docker-compose.yml      \n",
            "\u2514\u2500\u2500 projetFederaturBDBI.ipynb (training notebook)\n",
            "\n",
            "\ud83d\ude80 TO RUN LOCALLY:\n",
            "   1. pip install -r requirements.txt\n",
            "   2. uvicorn app:app --reload --port 8000\n",
            "   3. streamlit run streamlit_app.py (new terminal)\n",
            "\n",
            "\ud83d\udc33 TO RUN WITH DOCKER:\n",
            "   docker-compose up --build\n",
            "\n",
            "\ud83e\uddea TO RUN TESTS:\n",
            "   pytest test_app.py -v\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ============================================\n",
        "# Cell 1: Generate Deployment Files\n",
        "# ============================================\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"  GENERATING DEPLOYMENT FILES\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# ============================================\n",
        "# FILE 1: FastAPI Backend (app.py)\n",
        "# ============================================\n",
        "\n",
        "fastapi_code = '''\n",
        "from fastapi import FastAPI, UploadFile, File, HTTPException\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "from fastapi.responses import JSONResponse\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.models import efficientnet_b0\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import io\n",
        "import json\n",
        "import base64\n",
        "\n",
        "# ---- App Setup ----\n",
        "app = FastAPI(\n",
        "    title=\"Pneumonia Detection API\",\n",
        "    description=\"API de d\u00e9tection de pneumonie par analyse d'images radiographiques (Rayons X)\",\n",
        "    version=\"1.0.0\",\n",
        "    contact={\"name\": \"Ahmed Ben Attia Khiari & Achref Ghorbel\"}\n",
        ")\n",
        "\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=[\"*\"],\n",
        "    allow_methods=[\"*\"],\n",
        "    allow_headers=[\"*\"],\n",
        ")\n",
        "\n",
        "# ---- Model Loading ----\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "with open(\"model_config.json\", \"r\") as f:\n",
        "    config = json.load(f)\n",
        "\n",
        "model = efficientnet_b0(weights=None)\n",
        "model.classifier[1] = nn.Linear(1280, config[\"num_classes\"])\n",
        "model.load_state_dict(torch.load(\"best_model_crop.pt\", map_location=device))\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# ---- Transforms ----\n",
        "class DynamicCenterCrop:\n",
        "    def __init__(self, ratio=0.7):\n",
        "        self.ratio = ratio\n",
        "    def __call__(self, img):\n",
        "        w, h = img.size\n",
        "        new_w = int(w * self.ratio)\n",
        "        new_h = int(h * self.ratio)\n",
        "        left = (w - new_w) // 2\n",
        "        top = (h - new_h) // 2\n",
        "        return img.crop((left, top, left + new_w, top + new_h))\n",
        "\n",
        "inference_transform = transforms.Compose([\n",
        "    transforms.Lambda(lambda img: img.convert(\"RGB\")),\n",
        "    DynamicCenterCrop(config[\"center_crop_ratio\"]),\n",
        "    transforms.Resize((config[\"input_size\"], config[\"input_size\"])),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=config[\"normalization\"][\"mean\"],\n",
        "                         std=config[\"normalization\"][\"std\"])\n",
        "])\n",
        "\n",
        "raw_transform = transforms.Compose([\n",
        "    transforms.Lambda(lambda img: img.convert(\"RGB\")),\n",
        "    DynamicCenterCrop(config[\"center_crop_ratio\"]),\n",
        "    transforms.Resize((config[\"input_size\"], config[\"input_size\"])),\n",
        "])\n",
        "\n",
        "# ---- Grad-CAM ----\n",
        "class GradCAM:\n",
        "    def __init__(self, model, target_layer):\n",
        "        self.model = model\n",
        "        self.gradients = None\n",
        "        self.activations = None\n",
        "        target_layer.register_forward_hook(self._fwd)\n",
        "        target_layer.register_full_backward_hook(self._bwd)\n",
        "\n",
        "    def _fwd(self, module, input, output):\n",
        "        self.activations = output.detach()\n",
        "\n",
        "    def _bwd(self, module, grad_input, grad_output):\n",
        "        self.gradients = grad_output[0].detach()\n",
        "\n",
        "    def generate(self, input_tensor, target_class=None):\n",
        "        self.model.eval()\n",
        "        output = self.model(input_tensor)\n",
        "        if target_class is None:\n",
        "            target_class = output.argmax(dim=1).item()\n",
        "        self.model.zero_grad()\n",
        "        output[0, target_class].backward()\n",
        "        weights = self.gradients.mean(dim=[2, 3], keepdim=True)\n",
        "        cam = (weights * self.activations).sum(dim=1, keepdim=True)\n",
        "        cam = torch.relu(cam)\n",
        "        cam = torch.nn.functional.interpolate(cam, size=(224, 224), mode=\"bilinear\", align_corners=False)\n",
        "        cam = cam.squeeze().cpu().numpy()\n",
        "        if cam.max() > 0:\n",
        "            cam = cam / cam.max()\n",
        "        return cam, output\n",
        "\n",
        "grad_cam = GradCAM(model, model.features[-1])\n",
        "\n",
        "def generate_gradcam_image(img: Image.Image) -> str:\n",
        "    \"\"\"Generate Grad-CAM overlay and return as base64 string.\"\"\"\n",
        "    import matplotlib\n",
        "    matplotlib.use(\"Agg\")\n",
        "    import matplotlib.pyplot as plt\n",
        "    import matplotlib.cm as cm\n",
        "\n",
        "    tensor = inference_transform(img).unsqueeze(0).to(device)\n",
        "    heatmap, _ = grad_cam.generate(tensor)\n",
        "    \n",
        "    raw_img = np.array(raw_transform(img))\n",
        "    \n",
        "    colormap = cm.jet(heatmap)[:, :, :3]\n",
        "    colormap = (colormap * 255).astype(np.uint8)\n",
        "    \n",
        "    if raw_img.ndim == 2:\n",
        "        raw_img = np.stack([raw_img]*3, axis=-1)\n",
        "    \n",
        "    overlay = (0.6 * raw_img + 0.4 * colormap).astype(np.uint8)\n",
        "    \n",
        "    overlay_img = Image.fromarray(overlay)\n",
        "    buffer = io.BytesIO()\n",
        "    overlay_img.save(buffer, format=\"PNG\")\n",
        "    return base64.b64encode(buffer.getvalue()).decode(\"utf-8\")\n",
        "\n",
        "# ---- Routes ----\n",
        "@app.get(\"/\")\n",
        "async def root():\n",
        "    return {\n",
        "        \"message\": \"Pneumonia Detection API\",\n",
        "        \"version\": \"1.0.0\",\n",
        "        \"endpoints\": {\n",
        "            \"/predict\": \"POST - Upload X-ray image for prediction\",\n",
        "            \"/metrics\": \"GET - Model performance metrics\",\n",
        "            \"/health\": \"GET - API health check\"\n",
        "        }\n",
        "    }\n",
        "\n",
        "@app.get(\"/health\")\n",
        "async def health():\n",
        "    return {\"status\": \"healthy\", \"device\": str(device), \"model\": config[\"model_name\"]}\n",
        "\n",
        "@app.get(\"/metrics\")\n",
        "async def metrics():\n",
        "    return {\n",
        "        \"model\": config[\"model_name\"],\n",
        "        \"metrics\": config[\"metrics\"],\n",
        "        \"training\": config[\"training\"]\n",
        "    }\n",
        "\n",
        "@app.post(\"/predict\")\n",
        "async def predict(file: UploadFile = File(...)):\n",
        "    # Validate file\n",
        "    if not file.content_type or not file.content_type.startswith(\"image/\"):\n",
        "        raise HTTPException(status_code=400, detail=\"Le fichier doit \u00eatre une image (JPEG, PNG)\")\n",
        "    \n",
        "    try:\n",
        "        contents = await file.read()\n",
        "        img = Image.open(io.BytesIO(contents))\n",
        "    except Exception:\n",
        "        raise HTTPException(status_code=400, detail=\"Impossible de lire l'image\")\n",
        "    \n",
        "    # Predict\n",
        "    tensor = inference_transform(img).unsqueeze(0).to(device)\n",
        "    with torch.no_grad():\n",
        "        output = model(tensor)\n",
        "        probs = torch.softmax(output, dim=1)\n",
        "    \n",
        "    pred_idx = probs.argmax(dim=1).item()\n",
        "    confidence = probs[0][pred_idx].item()\n",
        "    \n",
        "    # Grad-CAM\n",
        "    gradcam_b64 = generate_gradcam_image(img)\n",
        "    \n",
        "    return JSONResponse(content={\n",
        "        \"prediction\": config[\"class_names\"][pred_idx],\n",
        "        \"confidence\": round(confidence * 100, 2),\n",
        "        \"probabilities\": {\n",
        "            \"NORMAL\": round(probs[0][0].item() * 100, 2),\n",
        "            \"PNEUMONIA\": round(probs[0][1].item() * 100, 2)\n",
        "        },\n",
        "        \"gradcam_image\": gradcam_b64\n",
        "    })\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    import uvicorn\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n",
        "'''\n",
        "\n",
        "with open(\"app.py\", \"w\") as f:\n",
        "    f.write(fastapi_code.strip())\n",
        "print(\"\u2705 Created: app.py (FastAPI backend)\")\n",
        "\n",
        "# ============================================\n",
        "# FILE 2: Streamlit Frontend (streamlit_app.py)\n",
        "# ============================================\n",
        "\n",
        "streamlit_code = '''\n",
        "import streamlit as st\n",
        "import requests\n",
        "from PIL import Image\n",
        "import io\n",
        "import base64\n",
        "import json\n",
        "\n",
        "# ---- Config ----\n",
        "API_URL = \"http://localhost:8000\"\n",
        "\n",
        "# ---- Page Setup ----\n",
        "st.set_page_config(\n",
        "    page_title=\"D\u00e9tection de Pneumonie\",\n",
        "    page_icon=\"\ud83e\udec1\",\n",
        "    layout=\"wide\"\n",
        ")\n",
        "\n",
        "# ---- Custom CSS ----\n",
        "st.markdown(\"\"\"\n",
        "<style>\n",
        "    .main-header {\n",
        "        text-align: center;\n",
        "        padding: 1rem;\n",
        "        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
        "        color: white;\n",
        "        border-radius: 10px;\n",
        "        margin-bottom: 2rem;\n",
        "    }\n",
        "    .metric-card {\n",
        "        background: #f8f9fa;\n",
        "        padding: 1.5rem;\n",
        "        border-radius: 10px;\n",
        "        border-left: 4px solid;\n",
        "        margin: 0.5rem 0;\n",
        "    }\n",
        "    .normal-result {\n",
        "        background: #d4edda;\n",
        "        border-color: #28a745;\n",
        "        padding: 2rem;\n",
        "        border-radius: 10px;\n",
        "        text-align: center;\n",
        "    }\n",
        "    .pneumonia-result {\n",
        "        background: #f8d7da;\n",
        "        border-color: #dc3545;\n",
        "        padding: 2rem;\n",
        "        border-radius: 10px;\n",
        "        text-align: center;\n",
        "    }\n",
        "</style>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "# ---- Header ----\n",
        "st.markdown(\"\"\"\n",
        "<div class=\"main-header\">\n",
        "    <h1>\ud83e\udec1 D\u00e9tection de Pneumonie par Rayons X</h1>\n",
        "    <p>Syst\u00e8me d'aide au diagnostic bas\u00e9 sur le Deep Learning (EfficientNet-B0)</p>\n",
        "    <p><em>Ahmed Ben Attia Khiari & Achref Ghorbel \u2014 Polytech International</em></p>\n",
        "</div>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "# ---- Sidebar ----\n",
        "with st.sidebar:\n",
        "    st.header(\"\u2139\ufe0f \u00c0 propos\")\n",
        "    st.markdown(\"\"\"\n",
        "    Ce syst\u00e8me utilise un mod\u00e8le **EfficientNet-B0** entra\u00een\u00e9 sur le dataset \n",
        "    **Chest X-Ray Images** pour d\u00e9tecter la pneumonie dans les radiographies thoraciques.\n",
        "    \n",
        "    **\u26a0\ufe0f Avertissement:** Ce syst\u00e8me est un outil d'aide au diagnostic \u00e0 usage acad\u00e9mique \n",
        "    uniquement. Il ne remplace pas l'avis d'un professionnel de sant\u00e9.\n",
        "    \"\"\")\n",
        "    \n",
        "    st.header(\"\ud83d\udcca M\u00e9triques du Mod\u00e8le\")\n",
        "    try:\n",
        "        resp = requests.get(f\"{API_URL}/metrics\", timeout=5)\n",
        "        if resp.status_code == 200:\n",
        "            data = resp.json()\n",
        "            m = data[\"metrics\"]\n",
        "            st.metric(\"Accuracy\", f\"{m['accuracy']*100:.1f}%\")\n",
        "            st.metric(\"AUC-ROC\", f\"{m['auc_roc']:.4f}\")\n",
        "            st.metric(\"Recall\", f\"{m['recall']*100:.1f}%\")\n",
        "            st.metric(\"Specificity\", f\"{m['specificity']*100:.1f}%\")\n",
        "            st.metric(\"F1-Score\", f\"{m['f1_score']:.4f}\")\n",
        "        else:\n",
        "            st.warning(\"API non disponible\")\n",
        "    except:\n",
        "        st.warning(\"\u26a0\ufe0f API non connect\u00e9e. Lancez: `uvicorn app:app --port 8000`\")\n",
        "\n",
        "# ---- Main Content ----\n",
        "col1, col2 = st.columns(2)\n",
        "\n",
        "with col1:\n",
        "    st.header(\"\ud83d\udce4 Upload Radiographie\")\n",
        "    uploaded_file = st.file_uploader(\n",
        "        \"Choisir une image radiographique (JPEG, PNG)\",\n",
        "        type=[\"jpg\", \"jpeg\", \"png\"],\n",
        "        help=\"Uploadez une radiographie thoracique pour analyse\"\n",
        "    )\n",
        "    \n",
        "    if uploaded_file:\n",
        "        image = Image.open(uploaded_file)\n",
        "        st.image(image, caption=\"Image upload\u00e9e\", use_container_width=True)\n",
        "\n",
        "with col2:\n",
        "    st.header(\"\ud83d\udd0d R\u00e9sultat\")\n",
        "    \n",
        "    if uploaded_file:\n",
        "        with st.spinner(\"Analyse en cours...\"):\n",
        "            try:\n",
        "                files = {\"file\": (uploaded_file.name, uploaded_file.getvalue(), uploaded_file.type)}\n",
        "                response = requests.post(f\"{API_URL}/predict\", files=files, timeout=30)\n",
        "                \n",
        "                if response.status_code == 200:\n",
        "                    result = response.json()\n",
        "                    prediction = result[\"prediction\"]\n",
        "                    confidence = result[\"confidence\"]\n",
        "                    \n",
        "                    # Result display\n",
        "                    if prediction == \"NORMAL\":\n",
        "                        st.markdown(f\"\"\"\n",
        "                        <div class=\"normal-result\">\n",
        "                            <h2>\u2705 {prediction}</h2>\n",
        "                            <h3>Confiance: {confidence}%</h3>\n",
        "                            <p>Aucun signe de pneumonie d\u00e9tect\u00e9</p>\n",
        "                        </div>\n",
        "                        \"\"\", unsafe_allow_html=True)\n",
        "                    else:\n",
        "                        st.markdown(f\"\"\"\n",
        "                        <div class=\"pneumonia-result\">\n",
        "                            <h2>\u26a0\ufe0f {prediction}</h2>\n",
        "                            <h3>Confiance: {confidence}%</h3>\n",
        "                            <p>Signes de pneumonie d\u00e9tect\u00e9s \u2014 Consultez un m\u00e9decin</p>\n",
        "                        </div>\n",
        "                        \"\"\", unsafe_allow_html=True)\n",
        "                    \n",
        "                    # Probabilities\n",
        "                    st.subheader(\"\ud83d\udcca Probabilit\u00e9s\")\n",
        "                    probs = result[\"probabilities\"]\n",
        "                    col_a, col_b = st.columns(2)\n",
        "                    col_a.metric(\"Normal\", f\"{probs['NORMAL']}%\")\n",
        "                    col_b.metric(\"Pneumonie\", f\"{probs['PNEUMONIA']}%\")\n",
        "                    \n",
        "                    # Progress bar\n",
        "                    st.progress(probs[\"PNEUMONIA\"] / 100)\n",
        "                    \n",
        "                    # Grad-CAM\n",
        "                    st.subheader(\"\ud83d\udd25 Carte d'attention (Grad-CAM)\")\n",
        "                    st.caption(\"Les zones rouges/jaunes indiquent o\u00f9 le mod\u00e8le concentre son attention\")\n",
        "                    gradcam_bytes = base64.b64decode(result[\"gradcam_image\"])\n",
        "                    gradcam_img = Image.open(io.BytesIO(gradcam_bytes))\n",
        "                    st.image(gradcam_img, caption=\"Grad-CAM Overlay\", use_container_width=True)\n",
        "                    \n",
        "                else:\n",
        "                    st.error(f\"Erreur API: {response.status_code}\")\n",
        "                    \n",
        "            except requests.exceptions.ConnectionError:\n",
        "                st.error(\"\u274c Impossible de se connecter \u00e0 l'API. Lancez: `uvicorn app:app --port 8000`\")\n",
        "            except Exception as e:\n",
        "                st.error(f\"Erreur: {str(e)}\")\n",
        "    else:\n",
        "        st.info(\"\ud83d\udc48 Uploadez une radiographie pour commencer l'analyse\")\n",
        "\n",
        "# ---- Footer ----\n",
        "st.markdown(\"---\")\n",
        "st.markdown(\"\"\"\n",
        "<div style=\"text-align: center; color: gray;\">\n",
        "    <p>Projet Deep Learning \u2014 D\u00e9tection de Pneumonie | Polytech International 2026</p>\n",
        "    <p>Professeur: Haythem Ghazouani</p>\n",
        "</div>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "'''\n",
        "\n",
        "with open(\"streamlit_app.py\", \"w\") as f:\n",
        "    f.write(streamlit_code.strip())\n",
        "print(\"\u2705 Created: streamlit_app.py (Streamlit frontend)\")\n",
        "\n",
        "# ============================================\n",
        "# FILE 3: Dockerfile\n",
        "# ============================================\n",
        "\n",
        "dockerfile = '''FROM python:3.10-slim\n",
        "\n",
        "WORKDIR /app\n",
        "\n",
        "# Install system deps\n",
        "RUN apt-get update && apt-get install -y --no-install-recommends \\\\\n",
        "    libgl1-mesa-glx libglib2.0-0 && \\\\\n",
        "    rm -rf /var/lib/apt/lists/*\n",
        "\n",
        "# Install Python deps\n",
        "COPY requirements.txt .\n",
        "RUN pip install --no-cache-dir -r requirements.txt\n",
        "\n",
        "# Copy app files\n",
        "COPY app.py .\n",
        "COPY streamlit_app.py .\n",
        "COPY best_model_crop.pt .\n",
        "COPY model_config.json .\n",
        "\n",
        "EXPOSE 8000 8501\n",
        "'''\n",
        "\n",
        "with open(\"Dockerfile\", \"w\") as f:\n",
        "    f.write(dockerfile.strip())\n",
        "print(\"\u2705 Created: Dockerfile\")\n",
        "\n",
        "# ============================================\n",
        "# FILE 4: docker-compose.yml\n",
        "# ============================================\n",
        "\n",
        "compose = '''version: \"3.8\"\n",
        "\n",
        "services:\n",
        "  api:\n",
        "    build: .\n",
        "    container_name: pneumonia-api\n",
        "    command: uvicorn app:app --host 0.0.0.0 --port 8000\n",
        "    ports:\n",
        "      - \"8000:8000\"\n",
        "    volumes:\n",
        "      - ./best_model_crop.pt:/app/best_model_crop.pt\n",
        "      - ./model_config.json:/app/model_config.json\n",
        "\n",
        "  frontend:\n",
        "    build: .\n",
        "    container_name: pneumonia-frontend\n",
        "    command: streamlit run streamlit_app.py --server.port 8501 --server.address 0.0.0.0\n",
        "    ports:\n",
        "      - \"8501:8501\"\n",
        "    depends_on:\n",
        "      - api\n",
        "    environment:\n",
        "      - API_URL=http://api:8000\n",
        "\n",
        "  mlflow:\n",
        "    image: python:3.10-slim\n",
        "    container_name: pneumonia-mlflow\n",
        "    command: bash -c \"pip install mlflow && mlflow ui --host 0.0.0.0 --port 5000\"\n",
        "    ports:\n",
        "      - \"5000:5000\"\n",
        "    volumes:\n",
        "      - ./mlruns:/mlruns\n",
        "'''\n",
        "\n",
        "with open(\"docker-compose.yml\", \"w\") as f:\n",
        "    f.write(compose.strip())\n",
        "print(\"\u2705 Created: docker-compose.yml\")\n",
        "\n",
        "# ============================================\n",
        "# FILE 5: requirements.txt\n",
        "# ============================================\n",
        "\n",
        "requirements = '''torch>=2.0.0\n",
        "torchvision>=0.15.0\n",
        "fastapi>=0.100.0\n",
        "uvicorn>=0.22.0\n",
        "python-multipart>=0.0.6\n",
        "streamlit>=1.30.0\n",
        "Pillow>=9.0.0\n",
        "numpy>=1.24.0\n",
        "matplotlib>=3.7.0\n",
        "requests>=2.28.0\n",
        "mlflow>=2.10.0\n",
        "'''\n",
        "\n",
        "with open(\"requirements.txt\", \"w\") as f:\n",
        "    f.write(requirements.strip())\n",
        "print(\"\u2705 Created: requirements.txt\")\n",
        "\n",
        "# ============================================\n",
        "# FILE 6: test_app.py (Pytest)\n",
        "# ============================================\n",
        "\n",
        "test_code = '''\n",
        "import pytest\n",
        "from fastapi.testclient import TestClient\n",
        "from app import app\n",
        "from PIL import Image\n",
        "import io\n",
        "import json\n",
        "import os\n",
        "\n",
        "client = TestClient(app)\n",
        "\n",
        "# ---- Test Health ----\n",
        "def test_health():\n",
        "    response = client.get(\"/health\")\n",
        "    assert response.status_code == 200\n",
        "    data = response.json()\n",
        "    assert data[\"status\"] == \"healthy\"\n",
        "    assert \"device\" in data\n",
        "    assert data[\"model\"] == \"EfficientNet-B0\"\n",
        "\n",
        "# ---- Test Root ----\n",
        "def test_root():\n",
        "    response = client.get(\"/\")\n",
        "    assert response.status_code == 200\n",
        "    data = response.json()\n",
        "    assert \"endpoints\" in data\n",
        "\n",
        "# ---- Test Metrics ----\n",
        "def test_metrics():\n",
        "    response = client.get(\"/metrics\")\n",
        "    assert response.status_code == 200\n",
        "    data = response.json()\n",
        "    assert \"metrics\" in data\n",
        "    assert data[\"metrics\"][\"accuracy\"] > 0.90\n",
        "    assert data[\"metrics\"][\"auc_roc\"] > 0.90\n",
        "\n",
        "# ---- Test Predict with valid image ----\n",
        "def test_predict_valid_image():\n",
        "    img = Image.new(\"RGB\", (224, 224), color=\"gray\")\n",
        "    buffer = io.BytesIO()\n",
        "    img.save(buffer, format=\"JPEG\")\n",
        "    buffer.seek(0)\n",
        "    \n",
        "    response = client.post(\"/predict\", files={\"file\": (\"test.jpg\", buffer, \"image/jpeg\")})\n",
        "    assert response.status_code == 200\n",
        "    data = response.json()\n",
        "    assert \"prediction\" in data\n",
        "    assert data[\"prediction\"] in [\"NORMAL\", \"PNEUMONIA\"]\n",
        "    assert \"confidence\" in data\n",
        "    assert 0 <= data[\"confidence\"] <= 100\n",
        "    assert \"probabilities\" in data\n",
        "    assert \"gradcam_image\" in data\n",
        "\n",
        "# ---- Test Predict with different sizes ----\n",
        "def test_predict_different_sizes():\n",
        "    for size in [(100, 100), (500, 500), (1024, 768)]:\n",
        "        img = Image.new(\"RGB\", size, color=\"white\")\n",
        "        buffer = io.BytesIO()\n",
        "        img.save(buffer, format=\"JPEG\")\n",
        "        buffer.seek(0)\n",
        "        response = client.post(\"/predict\", files={\"file\": (\"test.jpg\", buffer, \"image/jpeg\")})\n",
        "        assert response.status_code == 200\n",
        "\n",
        "# ---- Test Predict with PNG ----\n",
        "def test_predict_png():\n",
        "    img = Image.new(\"RGB\", (224, 224), color=\"gray\")\n",
        "    buffer = io.BytesIO()\n",
        "    img.save(buffer, format=\"PNG\")\n",
        "    buffer.seek(0)\n",
        "    response = client.post(\"/predict\", files={\"file\": (\"test.png\", buffer, \"image/png\")})\n",
        "    assert response.status_code == 200\n",
        "\n",
        "# ---- Test Config Exists ----\n",
        "def test_config_exists():\n",
        "    assert os.path.exists(\"model_config.json\")\n",
        "    with open(\"model_config.json\", \"r\") as f:\n",
        "        config = json.load(f)\n",
        "    assert config[\"model_name\"] == \"EfficientNet-B0\"\n",
        "    assert config[\"num_classes\"] == 2\n",
        "    assert config[\"center_crop_ratio\"] == 0.7\n",
        "\n",
        "# ---- Test Model File Exists ----\n",
        "def test_model_exists():\n",
        "    assert os.path.exists(\"best_model_crop.pt\")\n",
        "\n",
        "# ---- Test Gradcam is valid base64 ----\n",
        "def test_gradcam_base64():\n",
        "    img = Image.new(\"RGB\", (224, 224), color=\"gray\")\n",
        "    buffer = io.BytesIO()\n",
        "    img.save(buffer, format=\"JPEG\")\n",
        "    buffer.seek(0)\n",
        "    response = client.post(\"/predict\", files={\"file\": (\"test.jpg\", buffer, \"image/jpeg\")})\n",
        "    data = response.json()\n",
        "    import base64\n",
        "    decoded = base64.b64decode(data[\"gradcam_image\"])\n",
        "    assert len(decoded) > 0\n",
        "    gradcam_img = Image.open(io.BytesIO(decoded))\n",
        "    assert gradcam_img.size[0] > 0\n",
        "'''\n",
        "\n",
        "with open(\"test_app.py\", \"w\") as f:\n",
        "    f.write(test_code.strip())\n",
        "print(\"\u2705 Created: test_app.py (Pytest tests)\")\n",
        "\n",
        "# ============================================\n",
        "# Summary\n",
        "# ============================================\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"  ALL DEPLOYMENT FILES CREATED\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"\"\"\n",
        "\ud83d\udcc1 Project Structure:\n",
        "\u251c\u2500\u2500 best_model_crop.pt      (trained model)\n",
        "\u251c\u2500\u2500 model_config.json       (config & metrics)\n",
        "\u251c\u2500\u2500 app.py                  (FastAPI backend)\n",
        "\u251c\u2500\u2500 streamlit_app.py        (Streamlit frontend)\n",
        "\u251c\u2500\u2500 test_app.py             (Pytest tests)\n",
        "\u251c\u2500\u2500 requirements.txt        (dependencies)\n",
        "\u251c\u2500\u2500 Dockerfile              \n",
        "\u251c\u2500\u2500 docker-compose.yml      \n",
        "\u2514\u2500\u2500 projetFederaturBDBI.ipynb (training notebook)\n",
        "\n",
        "\ud83d\ude80 TO RUN LOCALLY:\n",
        "   1. pip install -r requirements.txt\n",
        "   2. uvicorn app:app --reload --port 8000\n",
        "   3. streamlit run streamlit_app.py (new terminal)\n",
        "\n",
        "\ud83d\udc33 TO RUN WITH DOCKER:\n",
        "   docker-compose up --build\n",
        "\n",
        "\ud83e\uddea TO RUN TESTS:\n",
        "   pytest test_app.py -v\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "9a4198d2-71df-49a8-abf1-fbb04e5aa75e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u2705 README.md created!\n",
            "   Location: C:\\Users\\mbena\\Downloads\\datasetProjetfed\\README.md\n"
          ]
        }
      ],
      "source": [
        "# ============================================\n",
        "# Cell 2: Generate README\n",
        "# ============================================\n",
        "\n",
        "readme = r'''# \ud83e\udec1 D\u00e9tection de Pneumonie par Analyse d'Images Radiographiques\n",
        "\n",
        "Syst\u00e8me d'aide au diagnostic bas\u00e9 sur le Deep Learning capable de classifier automatiquement les images radiographiques thoraciques (Rayons X) en deux cat\u00e9gories : **Normal** ou **Pneumonie**.\n",
        "\n",
        "## \ud83d\udc65 \u00c9quipe\n",
        "- **Ahmed Ben Attia Khiari**\n",
        "- **Achref Ghorbel**\n",
        "\n",
        "**Professeur :** Haythem Ghazouani  \n",
        "**Module :** Deep Learning \u2014 Computer Vision  \n",
        "**Institution :** Polytech International, 2026\n",
        "\n",
        "## \ud83d\udcca R\u00e9sultats\n",
        "\n",
        "| M\u00e9trique | Objectif | R\u00e9sultat |\n",
        "|----------|----------|----------|\n",
        "| Accuracy | > 90% | **97.9%** \u2705 |\n",
        "| AUC-ROC | > 0.90 | **0.9976** \u2705 |\n",
        "| Recall | > 85% | **98.6%** \u2705 |\n",
        "| Specificity | > 85% | **96.2%** \u2705 |\n",
        "| F1-Score | > 0.88 | **0.9860** \u2705 |\n",
        "\n",
        "## \ud83c\udfd7\ufe0f Architecture\n",
        "```\n",
        "Frontend (Streamlit:8501) \u2192 Backend (FastAPI:8000) \u2192 Mod\u00e8le (EfficientNet-B0)\n",
        "                                                    \u2193\n",
        "                                              MLflow (5000)\n",
        "```\n",
        "\n",
        "### Stack Technique\n",
        "- **Mod\u00e8le :** EfficientNet-B0 (pr\u00e9-entra\u00een\u00e9 ImageNet, fine-tun\u00e9)\n",
        "- **Framework :** PyTorch\n",
        "- **Backend :** FastAPI (API REST avec documentation Swagger)\n",
        "- **Frontend :** Streamlit\n",
        "- **Tracking :** MLflow\n",
        "- **Tests :** Pytest (9/9 \u2705)\n",
        "- **Conteneurisation :** Docker + Docker Compose\n",
        "\n",
        "## \ud83d\udcc1 Structure du Projet\n",
        "```\n",
        "\u251c\u2500\u2500 projetFederaturBDBI.ipynb   # Notebook: EDA + Training + Evaluation\n",
        "\u251c\u2500\u2500 deployment.ipynb            # Notebook: D\u00e9ploiement\n",
        "\u251c\u2500\u2500 app.py                      # Backend FastAPI\n",
        "\u251c\u2500\u2500 streamlit_app.py            # Frontend Streamlit\n",
        "\u251c\u2500\u2500 test_app.py                 # Tests Pytest\n",
        "\u251c\u2500\u2500 best_model_crop.pt          # Mod\u00e8le entra\u00een\u00e9\n",
        "\u251c\u2500\u2500 model_config.json           # Configuration du mod\u00e8le\n",
        "\u251c\u2500\u2500 requirements.txt            # D\u00e9pendances Python\n",
        "\u251c\u2500\u2500 Dockerfile                  # Image Docker\n",
        "\u251c\u2500\u2500 docker-compose.yml          # Orchestration Docker\n",
        "\u251c\u2500\u2500 Cahier_de_Charges.docx      # Cahier de charges\n",
        "\u2514\u2500\u2500 chest_xray/                 # Dataset\n",
        "    \u251c\u2500\u2500 train/\n",
        "    \u2502   \u251c\u2500\u2500 NORMAL/\n",
        "    \u2502   \u2514\u2500\u2500 PNEUMONIA/\n",
        "    \u2514\u2500\u2500 test/\n",
        "        \u251c\u2500\u2500 NORMAL/\n",
        "        \u2514\u2500\u2500 PNEUMONIA/\n",
        "```\n",
        "\n",
        "## \ud83d\udd2c M\u00e9thodologie\n",
        "\n",
        "### 1. Analyse Exploratoire (EDA)\n",
        "- Dataset : 5,840 images (Chest X-Ray Images \u2014 Kaggle)\n",
        "- Distribution : 1,575 NORMAL / 4,265 PNEUMONIA (d\u00e9s\u00e9quilibr\u00e9)\n",
        "- Source : Guangzhou Women and Children's Medical Center\n",
        "\n",
        "### 2. Pr\u00e9traitement & Augmentation\n",
        "- Conversion RGB, redimensionnement 224\u00d7224\n",
        "- Center Crop (70%) pour \u00e9liminer les artefacts de bord (IVs, tubes)\n",
        "- Augmentation : RandomHorizontalFlip, RandomRotation(10\u00b0), ColorJitter, RandomAffine\n",
        "- Normalisation ImageNet : mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
        "\n",
        "### 3. Entra\u00eenement\n",
        "- Architecture : EfficientNet-B0 (4M param\u00e8tres)\n",
        "- Optimiseur : Adam (LR=0.0005)\n",
        "- Scheduler : ReduceLROnPlateau (patience=2)\n",
        "- Split : 70% train / 15% val / 15% test (seed=42)\n",
        "- 12 \u00e9poques, meilleure validation : 97.6%\n",
        "\n",
        "### 4. \u00c9tude d'Ablation\n",
        "\n",
        "| Configuration | Accuracy | Specificity | Recall |\n",
        "|---------------|----------|-------------|--------|\n",
        "| V1: Class weights lourds | 85.6% | 62.0% | 99.7% |\n",
        "| V2: Class weights sqrt | 89.9% | 74.8% | 99.0% |\n",
        "| V4: Split 70/15/15 | 97.9% | 95.3% | 98.9% |\n",
        "| V5: + Center Crop (FINAL) | 97.9% | 96.2% | 98.6% |\n",
        "\n",
        "### 5. Interpr\u00e9tabilit\u00e9 (Grad-CAM)\n",
        "- D\u00e9tection de **shortcut learning** : le mod\u00e8le initial d\u00e9tectait les IVs/tubes au lieu des pathologies pulmonaires\n",
        "- Correction par Center Crop (70%) : ratio d'attention Pneumonia/Normal am\u00e9lior\u00e9 de 0.36 \u2192 0.68\n",
        "- Le mod\u00e8le final se concentre correctement sur les patterns pulmonaires\n",
        "\n",
        "## \ud83d\ude80 Installation & Utilisation\n",
        "\n",
        "### Pr\u00e9requis\n",
        "- Python 3.10+\n",
        "- CUDA compatible GPU (recommand\u00e9)\n",
        "\n",
        "### Installation\n",
        "```bash\n",
        "pip install -r requirements.txt\n",
        "```\n",
        "\n",
        "### Ex\u00e9cution locale\n",
        "```bash\n",
        "# Terminal 1: API Backend\n",
        "uvicorn app:app --port 8000\n",
        "\n",
        "# Terminal 2: Frontend\n",
        "streamlit run streamlit_app.py\n",
        "```\n",
        "Ouvrir http://localhost:8501 dans le navigateur.\n",
        "\n",
        "### Docker\n",
        "```bash\n",
        "docker-compose up --build\n",
        "```\n",
        "- Frontend : http://localhost:8501\n",
        "- API : http://localhost:8000\n",
        "- API Docs : http://localhost:8000/docs\n",
        "- MLflow : http://localhost:5000\n",
        "\n",
        "### Tests\n",
        "```bash\n",
        "pytest test_app.py -v\n",
        "```\n",
        "\n",
        "## \u26a0\ufe0f Consid\u00e9rations \u00c9thiques\n",
        "- Ce syst\u00e8me est un outil d'aide au diagnostic \u00e0 **usage acad\u00e9mique uniquement**\n",
        "- Il ne remplace pas l'avis d'un professionnel de sant\u00e9\n",
        "- Le dataset provient d'un seul h\u00f4pital (enfants chinois) \u2014 biais potentiel\n",
        "- Validation clinique n\u00e9cessaire avant tout usage m\u00e9dical r\u00e9el\n",
        "\n",
        "## \ud83d\udcc8 MLflow\n",
        "Les exp\u00e9riences sont track\u00e9es avec MLflow. Pour visualiser :\n",
        "```bash\n",
        "mlflow ui --port 5000\n",
        "```\n",
        "'''\n",
        "\n",
        "# Save\n",
        "target = r\"C:\\Users\\mbena\\Downloads\\datasetProjetfed\"\n",
        "\n",
        "with open(os.path.join(target, \"README.md\"), \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(readme.strip())\n",
        "\n",
        "print(\"\u2705 README.md created!\")\n",
        "print(f\"   Location: {os.path.join(target, 'README.md')}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (cv311 GPU)",
      "language": "python",
      "name": "cv311"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}